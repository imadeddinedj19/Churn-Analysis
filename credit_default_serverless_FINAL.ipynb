{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4f411b3-479b-4c6c-a2cd-ca14efb9aefc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Credit Default Prediction using Classical Machine Learning Models\n",
    "\n",
    "**Dataset:** UCI Credit Card Default  \n",
    "**Source table:** `workspace.default.default_of_credit_card_clients`  \n",
    "**Environment:** Databricks Serverless (SQL + Python)\n",
    "\n",
    "## Purpose of the Study\n",
    "The purpose of this study is to analyze customer credit behavior and evaluate whether\n",
    "classical machine learning models can predict credit card default. Credit default prediction\n",
    "is a core problem in financial risk management, as inaccurate decisions may lead to financial losses.\n",
    "\n",
    "We compare two interpretable models:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "\n",
    "The goal is not only predictive performance, but also interpretability and practical usability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d7972ed-5ab1-44a2-bb02-a238ddf7d7d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load raw table\n",
    "TABLE = \"workspace.default.default_of_credit_card_clients\"\n",
    "df_raw = spark.table(TABLE)\n",
    "display(df_raw.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "897ab137-32e9-44d1-952a-0822743f3338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cast all columns safely to INT and clean header row\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def safe_int(colname):\n",
    "    cleaned = F.trim(F.col(colname).cast(\"string\"))\n",
    "    cleaned = F.regexp_replace(cleaned, \",\", \"\")\n",
    "    is_number = cleaned.rlike(r\"^-?\\d+(\\.\\d+)?$\")\n",
    "    return (\n",
    "        F.when(is_number, cleaned.cast(\"double\").cast(\"int\"))\n",
    "         .otherwise(F.lit(None).cast(\"int\"))\n",
    "         .alias(colname)\n",
    "    )\n",
    "\n",
    "df = df_raw.select(*[safe_int(c) for c in df_raw.columns])\n",
    "\n",
    "# Drop header-as-row\n",
    "df = df.filter(F.col(\"_c0\").isNotNull())\n",
    "\n",
    "# Rename columns \n",
    "rename_map = {\n",
    "    \"_c0\": \"id\",\n",
    "    \"X1\": \"limit_bal\",\n",
    "    \"X2\": \"sex\",\n",
    "    \"X3\": \"education\",\n",
    "    \"X4\": \"marriage\",\n",
    "    \"X5\": \"age\",\n",
    "    \"X6\": \"pay_0\",\n",
    "    \"X7\": \"pay_2\",\n",
    "    \"X8\": \"pay_3\",\n",
    "    \"X9\": \"pay_4\",\n",
    "    \"X10\": \"pay_5\",\n",
    "    \"X11\": \"pay_6\",\n",
    "    \"X12\": \"bill_amt1\",\n",
    "    \"X13\": \"bill_amt2\",\n",
    "    \"X14\": \"bill_amt3\",\n",
    "    \"X15\": \"bill_amt4\",\n",
    "    \"X16\": \"bill_amt5\",\n",
    "    \"X17\": \"bill_amt6\",\n",
    "    \"X18\": \"pay_amt1\",\n",
    "    \"X19\": \"pay_amt2\",\n",
    "    \"X20\": \"pay_amt3\",\n",
    "    \"X21\": \"pay_amt4\",\n",
    "    \"X22\": \"pay_amt5\",\n",
    "    \"X23\": \"pay_amt6\",\n",
    "    \"Y\": \"default_payment_next_month\"\n",
    "}\n",
    "\n",
    "for old, new in rename_map.items():\n",
    "    if old in df.columns:\n",
    "        df = df.withColumnRenamed(old, new)\n",
    "\n",
    "df.printSchema()\n",
    "display(df.limit(5))\n",
    "\n",
    "df.createOrReplaceTempView(\"credit_default\")\n",
    "print(\"Temp view created: credit_default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5cdbdf8-f458-46c0-bfcc-e6a2a42ab5b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  COUNT(*) AS rows,\n",
    "  SUM(default_payment_next_month) AS defaults,\n",
    "  ROUND(AVG(default_payment_next_month),4) AS default_rate\n",
    "FROM credit_default;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88fb3bf1-637d-4c09-a06d-ca2b7548b62b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf = df.toPandas()\n",
    "\n",
    "pdf[\"default_payment_next_month\"].value_counts().plot(\n",
    "    kind=\"bar\", color=[\"#4DBBD5\", \"#E64B35\"]\n",
    ")\n",
    "plt.title(\"Class Balance: Default vs No Default\")\n",
    "plt.xlabel(\"Class (0 = No Default, 1 = Default)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot(\n",
    "    [pdf[pdf.default_payment_next_month==0].limit_bal,\n",
    "     pdf[pdf.default_payment_next_month==1].limit_bal],\n",
    "    labels=[\"No Default\", \"Default\"],\n",
    "    showfliers=False\n",
    ")\n",
    "plt.title(\"Credit Limit by Default Status\")\n",
    "plt.ylabel(\"Limit Balance\")\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot(\n",
    "    [pdf[pdf.default_payment_next_month==0].age,\n",
    "     pdf[pdf.default_payment_next_month==1].age],\n",
    "    labels=[\"No Default\", \"Default\"],\n",
    "    showfliers=False\n",
    ")\n",
    "plt.title(\"Age by Default Status\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "631dc8f8-b9e0-455f-ab4f-462712380630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_cols = pdf.select_dtypes(include=[np.number])\n",
    "corr = num_cols.corr()[\"default_payment_next_month\"].drop(\"default_payment_next_month\")\n",
    "corr.abs().sort_values(ascending=False).head(15).plot(\n",
    "    kind=\"barh\", figsize=(7,5)\n",
    ")\n",
    "plt.title(\"Top Correlations with Default\")\n",
    "plt.xlabel(\"Absolute Correlation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a04dd41b-fc7d-4462-9b29-490510b90a57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Machine Learning Models\n",
    "\n",
    "We split the data into training and test sets using stratification due to class imbalance.\n",
    "Both models use class weighting to compensate for the lower proportion of default cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "324c071f-daba-40c5-9d2a-69d3693d806a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "X = pdf.drop(columns=[\"default_payment_next_month\", \"id\"])\n",
    "y = pdf[\"default_payment_next_month\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "lr = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=3000, class_weight=\"balanced\"))\n",
    "])\n",
    "lr.fit(X_train, y_train)\n",
    "lr_prob = lr.predict_proba(X_test)[:,1]\n",
    "print(\"Logistic Regression AUC:\", roc_auc_score(y_test, lr_prob))\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=6, class_weight=\"balanced\", random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_prob = dt.predict_proba(X_test)[:,1]\n",
    "print(\"Decision Tree AUC:\", roc_auc_score(y_test, dt_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4420eed6-0ddb-4627-824f-19571248d089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "lr_pred = (lr_prob >= 0.5).astype(int)\n",
    "dt_pred = (dt_prob >= 0.5).astype(int)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, lr_pred)).plot(cmap=\"Blues\")\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, dt_pred)).plot(cmap=\"Blues\")\n",
    "plt.title(\"Decision Tree Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56a5357e-0e6e-4e25-a31a-6f9958f123da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Results & Conclusion\n",
    "\n",
    "- Both models are able to predict credit default better than random guessing.\n",
    "- Logistic Regression provides stable performance and strong interpretability.\n",
    "- Decision Tree captures non-linear relationships but may overfit.\n",
    "- Repayment status variables are the strongest predictors of default.\n",
    "\n",
    "**Conclusion:**  \n",
    "Classical machine learning models can effectively support credit risk assessment and\n",
    "provide actionable insights for financial decision-making.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7361213965982418,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "credit_default_serverless_FINAL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
